{
  "meta": {
    "experiment": "Exp-03-v2 Prompt Engineering (T+M Context)",
    "version": "v2",
    "date": "2026-02-10T17:19:17.937348",
    "sample_file": "../data/raw/files/고려대학교_차세대 포털·학사 정보시스템 구축사업.pdf",
    "num_test_cases": 30,
    "prerequisite": {
      "exp01v2_config": "T+M",
      "exp01v2_context_recall": 0.7904761904761906,
      "chunk_size": 500,
      "chunk_overlap": 50,
      "use_tables": true,
      "use_metadata": true,
      "alpha": 0.5,
      "top_k": 15,
      "gen_model": "gpt-5-mini"
    },
    "run_config": {
      "timeout": 300,
      "max_workers": 2
    }
  },
  "best_config": {
    "strategy": "few_shot_ko",
    "description": "한국어 Few-shot (2 examples)",
    "faithfulness": 0.9577777777777778,
    "answer_relevancy": 0.4037939167597329,
    "context_recall": 0.6666666666666666,
    "keyword_accuracy": 0.41608427820889116
  },
  "v1_comparison": {
    "zero_shot_en": {
      "faithfulness_delta": 0.05823104967326953,
      "keyword_accuracy_delta": -0.005159668333042822,
      "context_recall_delta": 0.033333333333333326
    },
    "zero_shot_ko": {
      "faithfulness_delta": -0.010867878829339372,
      "keyword_accuracy_delta": 0.0005742687824732418,
      "context_recall_delta": 0.0
    },
    "few_shot_ko": {
      "faithfulness_delta": 0.04671665925764301,
      "keyword_accuracy_delta": 0.005058183560505525,
      "context_recall_delta": -0.10000000000000009
    },
    "cot_ko": {
      "faithfulness_delta": null,
      "keyword_accuracy_delta": -0.012295048003252318,
      "context_recall_delta": -0.06666666666666676
    }
  },
  "strategies": [
    "zero_shot_en",
    "zero_shot_ko",
    "few_shot_ko",
    "cot_ko"
  ],
  "results": [
    {
      "strategy": "zero_shot_en",
      "description": "Baseline (영문 Zero-shot)",
      "faithfulness": 0.9229451265320832,
      "answer_relevancy": 0.588816141094918,
      "context_recall": 0.7333333333333333,
      "keyword_accuracy": 0.4351820765520457,
      "gen_time": 309.3977556999889,
      "ragas_time": 1295.6777637999621,
      "latency_total": 1605.0759148999932
    },
    {
      "strategy": "zero_shot_ko",
      "description": "한국어 Zero-shot",
      "faithfulness": 0.9523690932311621,
      "answer_relevancy": 0.4132632581495239,
      "context_recall": 0.7333333333333333,
      "keyword_accuracy": 0.4921943990248944,
      "gen_time": 350.18095020001056,
      "ragas_time": 1182.7050230000168,
      "latency_total": 1532.8865109999897
    },
    {
      "strategy": "few_shot_ko",
      "description": "한국어 Few-shot (2 examples)",
      "faithfulness": 0.9577777777777778,
      "answer_relevancy": 0.4037939167597329,
      "context_recall": 0.6666666666666666,
      "keyword_accuracy": 0.41608427820889116,
      "gen_time": 298.33881879999535,
      "ragas_time": 1018.1182504000026,
      "latency_total": 1316.4575061000069
    },
    {
      "strategy": "cot_ko",
      "description": "한국어 Chain-of-Thought",
      "faithfulness": 0.7359529064450493,
      "answer_relevancy": 0.5618573715772565,
      "context_recall": 0.7,
      "keyword_accuracy": 0.5942171977775693,
      "gen_time": 496.59266429999843,
      "ragas_time": 1496.451215100009,
      "latency_total": 1993.044513700006
    }
  ]
}