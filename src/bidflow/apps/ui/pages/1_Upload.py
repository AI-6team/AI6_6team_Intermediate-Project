import os
import shutil
import tempfile

import streamlit as st

from bidflow.apps.ui.auth import require_login
from bidflow.apps.ui.session import init_app_session
from bidflow.extraction.pipeline import ExtractionPipeline
from bidflow.ingest.loader import RFPLoader
from bidflow.ingest.storage import DocumentStore
from bidflow.security.rails.input_rail import SecurityException

st.set_page_config(page_title="Upload RFP", page_icon="ğŸ“‚", layout="wide")


def _signal_badge(signal: str) -> str:
    if signal == "GREEN":
        return "ğŸŸ¢ GREEN"
    if signal == "RED":
        return "ğŸ”´ RED"
    if signal == "GRAY":
        return "âšª GRAY"
    return signal


def _run_single_analysis(uploaded_file, user_id: str) -> None:
    with st.status("ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
        try:
            st.write("ğŸ“‚ ë¬¸ì„œë¥¼ ì„œë²„ì— ì €ì¥í•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤...")
            loader = RFPLoader(user_id=user_id)
            doc_hash = loader.process_file(uploaded_file, uploaded_file.name)
            st.write(f"âœ… íŒŒì‹± ì™„ë£Œ (ID: {doc_hash})")

            st.write("ğŸ§  Compliance Matrix ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤... (LLM)")
            pipeline = ExtractionPipeline(user_id=user_id)
            results = pipeline.run(doc_hash)
            st.write("âœ… ì¶”ì¶œ ì™„ë£Œ!")
        except SecurityException as e:
            status.update(label="ğŸš¨ ë³´ì•ˆ ìœ„í˜‘ íƒì§€!", state="error", expanded=True)
            st.error(f"ë³´ì•ˆ ìœ„í˜‘ì´ íƒì§€ë˜ì–´ ì²˜ë¦¬ê°€ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤: {e}")
            return
        except Exception as e:
            status.update(label="ì˜¤ë¥˜ ë°œìƒ", state="error")
            st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return

        st.session_state["current_doc_hash"] = doc_hash
        st.session_state["extraction_results"] = results
        st.session_state["analysis_success"] = True

        store = DocumentStore(user_id=user_id)
        store.save_extraction_result(doc_hash, results)
        store.save_session_state({"current_doc_hash": doc_hash})
        st.toast("ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", icon="ğŸ’¾")

        status.update(label="ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)


def _run_batch_analysis(uploaded_files, ragas_enabled: bool) -> None:
    from bidflow.extraction.batch_pipeline import BatchPipeline

    profile = st.session_state.get("company_profile")
    if not profile:
        st.error("íšŒì‚¬ í”„ë¡œí•„ì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œí•„ì„ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”.")
        return

    pipeline = BatchPipeline(company_profile=profile, ragas_enabled=ragas_enabled)

    tmp_dir = tempfile.mkdtemp(prefix="bidflow_batch_")
    file_paths = []
    try:
        for uf in uploaded_files:
            tmp_path = os.path.join(tmp_dir, uf.name)
            with open(tmp_path, "wb") as f:
                f.write(uf.getbuffer())
            file_paths.append(tmp_path)

        progress_bar = st.progress(0, text="ì¤€ë¹„ ì¤‘...")
        status_text = st.empty()

        def progress_callback(current, total, last_result):
            doc_name = last_result.doc_name if last_result else "..."
            signal = last_result.signal if last_result else ""
            progress_bar.progress(current / total, text=f"ì²˜ë¦¬ ì¤‘ {current}/{total}")
            if signal:
                status_text.write(f"ìµœê·¼ ì™„ë£Œ: **{doc_name}** â†’ {_signal_badge(signal)}")

        batch_result = pipeline.process_batch(file_paths, progress_cb=progress_callback)
        progress_bar.progress(1.0, text="ì™„ë£Œ!")
        status_text.empty()
        st.session_state["batch_result"] = batch_result
    except Exception as e:
        st.error(f"ì¼ê´„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        shutil.rmtree(tmp_dir, ignore_errors=True)


def _render_batch_result() -> None:
    if "batch_result" not in st.session_state:
        return

    batch = st.session_state["batch_result"]
    st.divider()
    st.subheader("ë‹¤ë¬¸ì„œ ë¶„ì„ ê²°ê³¼ ìš”ì•½")

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("ì „ì²´ ë¬¸ì„œ", batch.total_docs)
    col2.metric("ğŸŸ¢ GREEN", batch.green_count)
    col3.metric("ğŸ”´ RED", batch.red_count)
    col4.metric("âšª GRAY", batch.gray_count)
    st.caption(f"ì´ ì²˜ë¦¬ ì‹œê°„: {batch.total_processing_time_sec:.1f}ì´ˆ")

    if batch.failed_docs:
        with st.expander(f"âš ï¸ ì‹¤íŒ¨í•œ ë¬¸ì„œ ({len(batch.failed_docs)}ê±´)", expanded=True):
            for fd in batch.failed_docs:
                st.error(f"**{fd['name']}**: {fd['error']}")

    st.divider()
    signal_order = {"RED": 0, "GRAY": 1, "GREEN": 2}
    sorted_results = sorted(batch.results, key=lambda r: signal_order.get(r.signal, 1))
    st.subheader("ë¬¸ì„œë³„ ìƒì„¸ ê²°ê³¼")

    for doc_signal in sorted_results:
        badge = _signal_badge(doc_signal.signal)
        score_str = f"ì í•©ë„ {doc_signal.fit_score:.0%}"
        time_str = f"{doc_signal.processing_time_sec:.1f}s"

        with st.expander(f"{badge} **{doc_signal.doc_name}** â€” {score_str} ({time_str})"):
            mcol1, mcol2, mcol3 = st.columns(3)
            mcol1.metric("ì‹ í˜¸", doc_signal.signal)
            mcol2.metric("ì í•©ë„", f"{doc_signal.fit_score:.2f}")
            mcol3.metric("ì²˜ë¦¬ ì‹œê°„", f"{doc_signal.processing_time_sec:.1f}s")

            if doc_signal.signal_reasons:
                st.write("**íŒì • ì‚¬ìœ :**")
                for reason in doc_signal.signal_reasons:
                    st.write(f"- {reason}")

    st.divider()
    if st.button("ë‹¤ë¬¸ì„œ ê²°ê³¼ ì´ˆê¸°í™”"):
        st.session_state.pop("batch_result", None)
        st.rerun()


user_id = require_login()
init_app_session(user_id=user_id)

st.title("RFP ë¬¸ì„œ ì—…ë¡œë“œ")
st.caption("ë¬¸ì„œ 1ê°œ ì—…ë¡œë“œ ì‹œ ë‹¨ì¼ ë¶„ì„, 2ê°œ ì´ìƒ ì—…ë¡œë“œ ì‹œ ë‹¤ë¬¸ì„œ ì¼ê´„ ë¶„ì„ìœ¼ë¡œ ìë™ ì „í™˜ë©ë‹ˆë‹¤.")

with st.sidebar:
    st.subheader("ë¶„ì„ ì˜µì…˜")
    ragas_enabled = st.toggle(
        "ë‹¤ë¬¸ì„œ RAGAS í‰ê°€ (ì„ íƒ)",
        value=False,
        help="ë‹¤ë¬¸ì„œ ë¶„ì„ ì‹œ ë¬¸ì„œë‹¹ ì•½ 3ë¶„ ì¶”ê°€ ì†Œìš”ë©ë‹ˆë‹¤.",
    )

uploaded_files = st.file_uploader(
    "RFP ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF, HWP, DOCX, HWPX)",
    type=["pdf", "hwp", "docx", "hwpx"],
    accept_multiple_files=True,
)

if uploaded_files:
    st.info(f"{len(uploaded_files)}ê°œ íŒŒì¼ ì„ íƒë¨")
    for uf in uploaded_files:
        st.write(f"- {uf.name} ({uf.size:,} bytes)")

mode_label = "ë‹¨ì¼ ë¶„ì„" if len(uploaded_files) == 1 else "ë‹¤ë¬¸ì„œ ì¼ê´„ ë¶„ì„"
button_label = f"{mode_label} ì‹œì‘" if uploaded_files else "ë¶„ì„ ì‹œì‘"

if uploaded_files and st.button(button_label, type="primary"):
    if len(uploaded_files) == 1:
        st.session_state.pop("batch_result", None)
        st.session_state.pop("extraction_results", None)
        st.session_state["analysis_success"] = False
        _run_single_analysis(uploaded_files[0], user_id=user_id)
    else:
        st.session_state.pop("analysis_success", None)
        st.session_state.pop("extraction_results", None)
        _run_batch_analysis(uploaded_files, ragas_enabled=ragas_enabled)
        st.rerun()

if st.session_state.get("analysis_success"):
    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    try:
        st.page_link("pages/2_Matrix.py", label="ê²°ê³¼ ë³´ê¸° (Go to Matrix)", icon="ğŸ“Š")
    except AttributeError:
        if st.button("ê²°ê³¼ ë³´ê¸° (Go to Matrix)"):
            st.switch_page("pages/2_Matrix.py")

_render_batch_result()
