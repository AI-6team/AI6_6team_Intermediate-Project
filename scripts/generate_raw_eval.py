"""
exp09_phase2_raw_eval.csv ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    # í…ŒìŠ¤íŠ¸ (ì²« 3ê°œ íŒŒì¼ë§Œ)
    python scripts/generate_raw_eval.py --dry-run

    # ì „ì²´ ì‹¤í–‰
    python scripts/generate_raw_eval.py

    # íŠ¹ì • ëª¨ë¸ ì§€ì •
    python scripts/generate_raw_eval.py --model gpt-5-mini

í™˜ê²½ë³€ìˆ˜:
    OPENAI_API_KEY: OpenAI API í‚¤ (í•„ìˆ˜)
"""

import os
import sys
import csv
import json
import argparse
import subprocess
import time
from pathlib import Path
from typing import Optional, Dict, Tuple

# â”€â”€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent
DATA_DIR = PROJECT_ROOT / "data" / "raw" / "files"
EXPERIMENTS_DIR = PROJECT_ROOT / "data" / "experiments"
RAW_EVAL_CSV = EXPERIMENTS_DIR / "exp09_phase2_raw_eval.csv"
OUTPUT_CSV = EXPERIMENTS_DIR / "exp09_phase2_raw_eval.csv"

# dotenv ë¡œë“œ ì‹œë„
try:
    from dotenv import load_dotenv
    env_path = PROJECT_ROOT / ".env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extract_text_hwp(file_path: Path) -> str:
    """HWP íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ (hwp5txt â†’ olefile fallback)"""
    # 1ì°¨: hwp5txt CLI
    try:
        result = subprocess.run(
            ["hwp5txt", str(file_path)],
            capture_output=True, text=True,
            timeout=60, encoding="utf-8"
        )
        if result.returncode == 0 and result.stdout.strip():
            return result.stdout.strip()
    except FileNotFoundError:
        pass
    except subprocess.TimeoutExpired:
        print(f"  â³ hwp5txt timeout: {file_path.name}")
    except Exception as e:
        print(f"  âš ï¸ hwp5txt error: {e}")

    # 2ì°¨: olefile fallback
    try:
        import olefile
        import zlib
        text_parts = []
        with olefile.OleFileIO(str(file_path)) as ole:
            dirs = ole.listdir()
            body_sections = [
                d for d in dirs
                if d[0] == "BodyText" and d[1].startswith("Section")
            ]
            body_sections.sort(key=lambda x: int(x[1].replace("Section", "")))

            for section in body_sections:
                data = ole.openstream(section).read()
                try:
                    decompressed = zlib.decompress(data, -15)
                except zlib.error:
                    decompressed = data
                raw_text = decompressed.decode("utf-16-le", errors="ignore")
                text_parts.append(raw_text)

        return "\n\n".join(text_parts)
    except Exception as e:
        print(f"  âš ï¸ olefile error: {e}")
        return ""


def extract_text_pdf(file_path: Path) -> str:
    """PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ (pdfplumber)"""
    try:
        import pdfplumber
        texts = []
        with pdfplumber.open(str(file_path)) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    texts.append(text)
        return "\n\n".join(texts)
    except Exception as e:
        print(f"  âš ï¸ pdfplumber error: {e}")
        return ""


def extract_text(file_path: Path) -> str:
    """íŒŒì¼ í™•ì¥ìì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    ext = file_path.suffix.lower()
    if ext == ".hwp":
        return extract_text_hwp(file_path)
    elif ext == ".pdf":
        return extract_text_pdf(file_path)
    else:
        print(f"  âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {ext}")
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. LLM ê¸°ë°˜ Q/A ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

GENERATE_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ ê³µê³µì¡°ë‹¬ ì…ì°° ë¬¸ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì…ì°° ë¬¸ì„œ ë‚´ìš©ì„ ì½ê³ , ì´ ë¬¸ì„œì— ëŒ€í•œ **í‰ê°€ ì§ˆë¬¸ 1ê°œ**ì™€ **ì •ë‹µ(ground_truth)**, ê·¸ë¦¬ê³  **ëª¨ë²” ë‹µë³€(answer)**ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ì„¸ìš”.

## ì§ˆë¬¸ ìƒì„± ê·œì¹™
1. ë¬¸ì„œì—ì„œ **ëª…í™•í•˜ê²Œ ë‹µì„ ì°¾ì„ ìˆ˜ ìˆëŠ”** ì‚¬ì‹¤ ê¸°ë°˜ ì§ˆë¬¸ì„ ë§Œë“œì„¸ìš”.
2. ì§ˆë¬¸ ìœ í˜•ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”: ì‚¬ì—…ëª…, ì‚¬ì—…ê¸°ê°„, ì‚¬ì—…ì˜ˆì‚°, ì…ì°°ë°©ì‹, ìê²©ìš”ê±´, ìˆ˜í–‰ì¥ì†Œ, í•˜ìë³´ìˆ˜, ë³´ì•ˆìš”êµ¬ì‚¬í•­, ì‹œìŠ¤í…œêµ¬ì¶•ë²”ìœ„, ì£¼ìš”ê¸°ëŠ¥
3. ground_truthëŠ” ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•œ **ì •í™•í•œ ì •ë‹µ**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
4. answerëŠ” ground_truthì™€ ê°™ì€ ì˜ë¯¸ì´ë˜, ì¢€ ë” ìì—°ìŠ¤ëŸ¬ìš´ **ë¬¸ì¥í˜• ë‹µë³€**ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
5. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹ (JSONë§Œ ì¶œë ¥, ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´)
{{"question": "ì§ˆë¬¸ ë‚´ìš©", "ground_truth": "ì •ë‹µ", "answer": "ë¬¸ì¥í˜• ë‹µë³€"}}

## ë¬¸ì„œ ë‚´ìš© (ì•ë¶€ë¶„ ë°œì·Œ)
{context}
"""


def generate_qa(
    text: str,
    filename: str,
    model: str = "gpt-5-mini",
    api_key: Optional[str] = None,
) -> Dict[str, str]:
    """OpenAI APIë¡œ question/ground_truth/answer ìƒì„±"""
    try:
        from openai import OpenAI
    except ImportError:
        print("âŒ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. pip install openai")
        sys.exit(1)

    client = OpenAI(api_key=api_key or os.getenv("OPENAI_API_KEY"))

    # ì»¨í…ìŠ¤íŠ¸ 3000ì ì œí•œ (í† í° ì ˆì•½)
    context = text[:3000] if len(text) > 3000 else text

    if not context.strip():
        # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ íŒŒì¼ëª… ê¸°ë°˜ìœ¼ë¡œ ìµœì†Œí•œì˜ Q/A ìƒì„±
        context = f"ì‚¬ì—…ëª…: {filename}"

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": GENERATE_PROMPT.format(context=context)}
            ],
            response_format={"type": "json_object"},
        )
        raw = response.choices[0].message.content.strip()
        result = json.loads(raw)

        # í•„ìˆ˜ í‚¤ ê²€ì¦
        for key in ("question", "ground_truth", "answer"):
            if key not in result:
                result[key] = ""

        return result

    except Exception as e:
        print(f"  âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨ ({filename}): {e}")
        return {
            "question": f"ë³¸ ì‚¬ì—…ì˜ í”„ë¡œì íŠ¸ ëª…ì€ ë¬´ì—‡ì¸ê°€?",
            "ground_truth": filename.rsplit("_", 1)[-1].replace(".hwp", "").replace(".pdf", ""),
            "answer": f"íŒŒì¼ëª…ì— ë”°ë¥´ë©´ ë³¸ ì‚¬ì—…ì€ '{filename}'ì…ë‹ˆë‹¤."
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. CSV ì—…ë°ì´íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_csv(path: Path) -> list:
    """CSVë¥¼ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œ"""
    with open(path, "r", encoding="utf-8-sig") as f:
        reader = csv.DictReader(f)
        return list(reader), reader.fieldnames


def save_csv(path: Path, rows: list, fieldnames: list):
    """dict ë¦¬ìŠ¤íŠ¸ë¥¼ CSVë¡œ ì €ì¥"""
    with open(path, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. ë©”ì¸ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(description="exp09 raw eval CSV ìë™ ìƒì„±")
    parser.add_argument("--dry-run", action="store_true", help="ì²« 3ê°œ íŒŒì¼ë§Œ ì²˜ë¦¬")
    parser.add_argument("--model", default="gpt-5-mini", help="OpenAI ëª¨ë¸ëª… (ê¸°ë³¸: gpt-5-mini)")
    parser.add_argument("--api-key", default=None, help="OpenAI API í‚¤ (ë¯¸ì§€ì • ì‹œ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)")
    args = parser.parse_args()

    # API í‚¤ í™•ì¸
    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   export OPENAI_API_KEY=sk-... ë˜ëŠ” --api-key ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(1)

    # CSV ë¡œë“œ
    if not RAW_EVAL_CSV.exists():
        print(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {RAW_EVAL_CSV}")
        sys.exit(1)

    rows, fieldnames = load_csv(RAW_EVAL_CSV)
    print(f"ğŸ“„ CSV ë¡œë“œ ì™„ë£Œ: {len(rows)}í–‰, ì»¬ëŸ¼: {fieldnames}")

    # ê³ ìœ  íŒŒì¼ëª… ì¶”ì¶œ
    unique_files = list(dict.fromkeys(row["file"] for row in rows))
    print(f"ğŸ“‚ ê³ ìœ  ë¬¸ì„œ ìˆ˜: {len(unique_files)}")

    if args.dry_run:
        unique_files = unique_files[:3]
        print(f"ğŸ§ª Dry-run ëª¨ë“œ: ì²« {len(unique_files)}ê°œ íŒŒì¼ë§Œ ì²˜ë¦¬")

    # tqdm ì‚¬ìš© ì‹œë„
    try:
        from tqdm import tqdm
        file_iter = tqdm(unique_files, desc="ë¬¸ì„œ ì²˜ë¦¬ ì¤‘")
    except ImportError:
        file_iter = unique_files
        print("ğŸ’¡ tqdm ë¯¸ì„¤ì¹˜ â†’ ì§„í–‰ë¥  ë°” ì—†ì´ ì‹¤í–‰í•©ë‹ˆë‹¤.")

    # íŒŒì¼ë³„ Q/A ìƒì„±
    qa_cache: Dict[str, Dict[str, str]] = {}
    success_count = 0
    fail_count = 0

    for filename in file_iter:
        # íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
        file_path = DATA_DIR / filename
        if not file_path.exists():
            print(f"  âš ï¸ íŒŒì¼ ì—†ìŒ: {filename}")
            qa_cache[filename] = {
                "question": "",
                "ground_truth": "",
                "answer": ""
            }
            fail_count += 1
            continue

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = extract_text(file_path)
        if not text.strip():
            print(f"  âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {filename}")
            text = ""

        # Q/A ìƒì„±
        qa = generate_qa(text, filename, model=args.model, api_key=api_key)
        qa_cache[filename] = qa
        success_count += 1

        # API rate limit ë°©ì§€
        time.sleep(0.5)

    print(f"\nâœ… Q/A ìƒì„± ì™„ë£Œ: ì„±ê³µ {success_count} / ì‹¤íŒ¨ {fail_count}")

    # CSV ì—…ë°ì´íŠ¸
    updated_count = 0
    for row in rows:
        filename = row["file"]
        if filename in qa_cache:
            qa = qa_cache[filename]
            row["question"] = qa.get("question", "")
            row["ground_truth"] = qa.get("ground_truth", "")
            row["answer"] = qa.get("answer", "")
            if qa.get("question"):
                updated_count += 1

    # ì €ì¥
    if args.dry_run:
        output_path = EXPERIMENTS_DIR / "exp09_phase2_raw_eval_dryrun.csv"
    else:
        output_path = OUTPUT_CSV

    save_csv(output_path, rows, fieldnames)
    print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"   ì—…ë°ì´íŠ¸ëœ í–‰: {updated_count} / {len(rows)}")

    # ë¹ˆ ì…€ ë¦¬í¬íŠ¸
    empty_q = sum(1 for r in rows if not r.get("question"))
    empty_gt = sum(1 for r in rows if not r.get("ground_truth"))
    empty_a = sum(1 for r in rows if not r.get("answer"))
    print(f"\nğŸ“Š ë¹ˆ ì…€ í˜„í™©:")
    print(f"   question:     {empty_q} / {len(rows)} ë¹ˆ ì…€")
    print(f"   ground_truth: {empty_gt} / {len(rows)} ë¹ˆ ì…€")
    print(f"   answer:       {empty_a} / {len(rows)} ë¹ˆ ì…€")


if __name__ == "__main__":
    main()
